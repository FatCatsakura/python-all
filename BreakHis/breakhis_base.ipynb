{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_seg(img,label):\n",
    "    hight,width = img.size\n",
    "    w = 32\n",
    "    id = 0\n",
    "    j = 6\n",
    "    new_imgs = []\n",
    "    while(j + w <= width):\n",
    "        i = 14\n",
    "        while(i +w <= hight):\n",
    "            new_imgs.append((img.crop((i, j, i + w, j + w)).convert('RGB'),label))\n",
    "            id += 1\n",
    "            i += w\n",
    "        j += w\n",
    "#    print(hight,width,id)\n",
    "    return new_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, datatxt, datatype,transform = None, target_transform = None):\n",
    "        super(MyDataSet,self).__init__()\n",
    "        fh = open(root + datatxt, 'r')\n",
    "        imgs = []\n",
    "       # j = 0\n",
    "        for line in fh:\n",
    "            columns = line.split('|')\n",
    "            if columns[3].replace(\"\\n\",\"\") == datatype:\n",
    "                imgname = columns[0]\n",
    "                imglb = imgname[4]\n",
    "                if imglb == 'B':\n",
    "                    imglb = 0\n",
    "                else:\n",
    "                    imglb = 1\n",
    "                lb = []\n",
    "                mag = columns[1]  # 40, 100, 200, or 400\n",
    "                fold = columns[2]\n",
    "                img = Image.open((root + '%s/' + '%sX/' + imgname )% (datatype,mag)).convert('RGB')\n",
    "                new_img = img_seg(img,imglb)\n",
    "                imgs.extend(new_img)\n",
    "        #        j = j+1\n",
    "        #        if imglb == 'M':\n",
    "        #            print(j,new_labels,'\\n')\n",
    "         \n",
    "                \n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img,target = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './fold2/'\n",
    "fold2_train_data = MyDataSet(root = root,datatxt = 'dsfold2.txt',datatype = 'train',transform = torchvision.transforms.ToTensor())\n",
    "fold2_test_data = MyDataSet(root = root,datatxt = 'dsfold2.txt',datatype = 'test',transform = torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.7843, 0.7725, 0.7608,  ..., 0.7569, 0.7569, 0.7647],\n",
      "         [0.7686, 0.7686, 0.7569,  ..., 0.8118, 0.8157, 0.8039],\n",
      "         [0.7725, 0.7647, 0.7569,  ..., 0.8196, 0.8078, 0.7922],\n",
      "         ...,\n",
      "         [0.7412, 0.7686, 0.7765,  ..., 0.7176, 0.7216, 0.7216],\n",
      "         [0.7412, 0.7686, 0.7647,  ..., 0.7137, 0.7098, 0.7216],\n",
      "         [0.7451, 0.7490, 0.7373,  ..., 0.7294, 0.7294, 0.7529]],\n",
      "\n",
      "        [[0.5725, 0.5725, 0.5804,  ..., 0.7020, 0.7020, 0.7020],\n",
      "         [0.5686, 0.5765, 0.5804,  ..., 0.7569, 0.7608, 0.7412],\n",
      "         [0.5804, 0.5804, 0.5882,  ..., 0.7608, 0.7529, 0.7373],\n",
      "         ...,\n",
      "         [0.6549, 0.6863, 0.7020,  ..., 0.6314, 0.6392, 0.6314],\n",
      "         [0.6549, 0.6863, 0.6941,  ..., 0.6392, 0.6353, 0.6471],\n",
      "         [0.6706, 0.6667, 0.6667,  ..., 0.6627, 0.6627, 0.6863]],\n",
      "\n",
      "        [[0.7059, 0.6941, 0.6941,  ..., 0.7608, 0.7608, 0.7529],\n",
      "         [0.6980, 0.7020, 0.6941,  ..., 0.8235, 0.8275, 0.7922],\n",
      "         [0.7059, 0.7059, 0.7059,  ..., 0.8353, 0.8196, 0.8039],\n",
      "         ...,\n",
      "         [0.7373, 0.7608, 0.7765,  ..., 0.7137, 0.7137, 0.7098],\n",
      "         [0.7373, 0.7608, 0.7569,  ..., 0.7137, 0.7098, 0.7216],\n",
      "         [0.7451, 0.7412, 0.7294,  ..., 0.7333, 0.7333, 0.7490]]]), 0) \n",
      "\n",
      "tensor([[[0.7843, 0.7725, 0.7608,  ..., 0.7569, 0.7569, 0.7647],\n",
      "         [0.7686, 0.7686, 0.7569,  ..., 0.8118, 0.8157, 0.8039],\n",
      "         [0.7725, 0.7647, 0.7569,  ..., 0.8196, 0.8078, 0.7922],\n",
      "         ...,\n",
      "         [0.7412, 0.7686, 0.7765,  ..., 0.7176, 0.7216, 0.7216],\n",
      "         [0.7412, 0.7686, 0.7647,  ..., 0.7137, 0.7098, 0.7216],\n",
      "         [0.7451, 0.7490, 0.7373,  ..., 0.7294, 0.7294, 0.7529]],\n",
      "\n",
      "        [[0.5725, 0.5725, 0.5804,  ..., 0.7020, 0.7020, 0.7020],\n",
      "         [0.5686, 0.5765, 0.5804,  ..., 0.7569, 0.7608, 0.7412],\n",
      "         [0.5804, 0.5804, 0.5882,  ..., 0.7608, 0.7529, 0.7373],\n",
      "         ...,\n",
      "         [0.6549, 0.6863, 0.7020,  ..., 0.6314, 0.6392, 0.6314],\n",
      "         [0.6549, 0.6863, 0.6941,  ..., 0.6392, 0.6353, 0.6471],\n",
      "         [0.6706, 0.6667, 0.6667,  ..., 0.6627, 0.6627, 0.6863]],\n",
      "\n",
      "        [[0.7059, 0.6941, 0.6941,  ..., 0.7608, 0.7608, 0.7529],\n",
      "         [0.6980, 0.7020, 0.6941,  ..., 0.8235, 0.8275, 0.7922],\n",
      "         [0.7059, 0.7059, 0.7059,  ..., 0.8353, 0.8196, 0.8039],\n",
      "         ...,\n",
      "         [0.7373, 0.7608, 0.7765,  ..., 0.7137, 0.7137, 0.7098],\n",
      "         [0.7373, 0.7608, 0.7569,  ..., 0.7137, 0.7098, 0.7216],\n",
      "         [0.7451, 0.7412, 0.7294,  ..., 0.7333, 0.7333, 0.7490]]]) \n",
      "\n",
      "0 \n",
      "\n",
      "tensor([[0.5725, 0.5725, 0.5804,  ..., 0.7020, 0.7020, 0.7020],\n",
      "        [0.5686, 0.5765, 0.5804,  ..., 0.7569, 0.7608, 0.7412],\n",
      "        [0.5804, 0.5804, 0.5882,  ..., 0.7608, 0.7529, 0.7373],\n",
      "        ...,\n",
      "        [0.6549, 0.6863, 0.7020,  ..., 0.6314, 0.6392, 0.6314],\n",
      "        [0.6549, 0.6863, 0.6941,  ..., 0.6392, 0.6353, 0.6471],\n",
      "        [0.6706, 0.6667, 0.6667,  ..., 0.6627, 0.6627, 0.6863]])\n"
     ]
    }
   ],
   "source": [
    "print(fold2_train_data[0],'\\n') #first sample\n",
    "print(fold2_train_data[0][0],'\\n') #pixels of first sample\n",
    "print(fold2_train_data[0][1],'\\n') #label of first sample\n",
    "print(fold2_train_data[0][0][1]) #first channel of pixels of first sample(RGB have three channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 3 2 1618764\n"
     ]
    }
   ],
   "source": [
    "a =len(fold2_train_data[0][0][0])\n",
    "b =len(fold2_train_data[0][0])\n",
    "c =len(fold2_train_data)\n",
    "d =len(fold2_train_data[0])\n",
    "print(a,b,d,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwarg = {'num_workers': 1,'pin_memory': True}\n",
    "trainloader2 = torch.utils.data.DataLoader(dataset = fold2_train_data,batch_size=64,shuffle = True, **kwarg)\n",
    "testloader2 = torch.utils.data.DataLoader(dataset = fold2_test_data,batch_size=64,shuffle = True, **kwarg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
